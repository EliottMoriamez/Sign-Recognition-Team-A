{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f7b7b29a9a488aa",
   "metadata": {},
   "source": [
    "# Sign Recognition Project\n",
    "\n",
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1eaa5",
   "metadata": {},
   "source": [
    "# State of the Art in Traffic Sign Recognition\n",
    "\n",
    "Traffic sign recognition had major technological shifts over the last few decades.\n",
    "Early systems relied on classic computer vision pipelines,  based on hand-crafted features and segmentation algorithms. Techniques such as HOG (Histogram of Oriented Gradients), color thresholding, and shape-based segmentation were used to isolate candidate signs before applying classifiers like SVMs or Random Forests. While these methods were simple and lightweight, they suffered from significant limitations such as poor accuracy on low-quality or blurry images, difficulty handling multiple signs in the same scene or high sensitivity to lighting changes, occlusion, and weather\n",
    "\n",
    "As a result, classical pipelines often produced unstable or inaccurate predictions, especially in complex real-world environments.\n",
    "\n",
    "### Transition to Deep Learning\n",
    "\n",
    "The introduction of deep neural networks (DNNs) greatly improved traffic sign recognition.\n",
    "CNNs (Convolutional Neural Networks) replaced manual feature engineering, learning directly from pixel data and providing large accuracy improvements.\n",
    "\n",
    "The next major leap came with end-to-end object detection networks, primarily the YOLO (You Only Look Once) family. YOLO models perform both detection and classification simultaneously, which is great for real time detection in autonomous driving and offers great robustness to bad quality pictures and overlapping signs as well as change of lightning, blur and complex backgrounds. These strong capabilities make YOLO the current standart in this domain.\n",
    "\n",
    "To provide such accuracy and strength these YOLO based models rely on very large datasets such as the GTSRB with 50,000 labeled images in 43 sign classes and the MTSD with over 100 000 images from many countries covering hundreds of sign types in various light and quality conditions\n",
    "\n",
    "\n",
    "\n",
    "### Performance and Current Capabilities\n",
    "\n",
    "State-of-the-art deep learning systems show performances better than humans with up to 99.8% accuracy in record time. These results, previously unacheivable on older algorithms now unable real time uses in embedded hardware, mostly in autonomous vehicles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51a437d",
   "metadata": {},
   "source": [
    "## Traffic Sign Recognition Using Scikit-Learn\n",
    "\n",
    "Scikit-learn offers several effective algorithms that can be used with handcrafted image features such as HOG, PCA-reduced pixels, or color/shape descriptors.\n",
    "\n",
    "We have found four classical models available in scikit-learn that could have fit our use case:\n",
    "\n",
    "- Multinomial Logistic Regression  \n",
    "- Support Vector Machine (SVM)  \n",
    "- Gaussian Naive Bayes  \n",
    "- K-Nearest Neighbors (k-NN)  \n",
    "\n",
    "\n",
    "### 1. Multinomial Logistic Regression\n",
    "\n",
    "Multinomial Logistic Regression is a linear classifier that models class probabilities with a softmax function. It attempts to find a linear decision boundary between classes.\n",
    "It has a very fast training and prediction time, is relativly simple to interpret and understand and as overall good performances however it struggles with visual variations and other similar complex images, needs preprocessing of the images and is very sensitive to lighting conditions.\n",
    "\n",
    "### 2. Support Vector Machine (SVM)\n",
    "\n",
    "SVM identifies a separating hyperplane that maximizes the margin between classes. With the RBF kernel, SVM can model highly non-linear decision boundaries.\n",
    "It provides a high accuracy with strong robustness to noise and background informations but is slow to train and needs high quantity of memory to run.\n",
    "It performs very good on quality datasets and when computation time is not a issue.\n",
    "\n",
    "### 3. Gaussian Naive Bayes\n",
    "\n",
    "Gaussian Naive Bayes models each feature as an independent Gaussian distribution and computes likelihoods per class.\n",
    "It is very fast to train and needs only simple features to work as it has no hyperparameter to tune it also needs very little computation. But it suffers from poor accuracy when dealing with related images or when working on complex datasets.\n",
    "\n",
    "\n",
    "### 4. K-Nearest Neighbors (k-NN)\n",
    "\n",
    "k-NN stores the entire dataset and predicts class labels by comparing the test sample to its k closest training samples in feature space.\n",
    "It has no training cost ans is very simple to implement however needs quite a lot of computation time and memory usages and lack performance in large complex datasets.\n",
    "\n",
    "\n",
    "\n",
    "### Final Notes\n",
    "\n",
    "Traffic sign recognition with scikit-learn is feasible but relies heavily on **feature extraction**, since scikit-learn does not include convolutional neural networks (CNNs).  \n",
    "Among classical models, **SVM with HOG features** consistently provides the best accuracy and robustness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8313086-bcfc-4d29-ac44-8bc568bce844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:35:39.940854Z",
     "start_time": "2025-12-07T12:35:39.927769Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196dd488d4d4633f",
   "metadata": {},
   "source": [
    "### Dataset Extraction\n",
    "\n",
    "Parsing the XML and loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2cafa-94f9-4cba-ad31-f9888adf6d80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:35:39.985910Z",
     "start_time": "2025-12-07T12:35:39.970187Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = \".\"\n",
    "IMAGES_DIR = \"./road-sign-detection/images\"\n",
    "ANN_DIR = \"./road-sign-detection/annotations\"\n",
    "\n",
    "print(\"Number of images :\", len(os.listdir(IMAGES_DIR)))\n",
    "print(\"Number of annotations :\", len(os.listdir(ANN_DIR)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf485bdf221ce17",
   "metadata": {},
   "source": [
    "We had to delete a few annotations files as it was causing errors, there was a few speedlimit signs that had only one occurrence, which is not enough to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411a98f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:35:40.140439Z",
     "start_time": "2025-12-07T12:35:40.128312Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_voc_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    filename = root.find(\"filename\").text\n",
    "    objects = []\n",
    "    \n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = obj.find(\"name\").text\n",
    "        bnd = obj.find(\"bndbox\")\n",
    "        xmin = int(bnd.find(\"xmin\").text)\n",
    "        ymin = int(bnd.find(\"ymin\").text)\n",
    "        xmax = int(bnd.find(\"xmax\").text)\n",
    "        ymax = int(bnd.find(\"ymax\").text)\n",
    "        objects.append({\n",
    "            \"label\": name,\n",
    "            \"bbox\": (xmin, ymin, xmax, ymax)\n",
    "        })\n",
    "    \n",
    "    return filename, objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeabf84a1fd23d5a",
   "metadata": {},
   "source": [
    "### Images formatting\n",
    "\n",
    "We crop the images to keep only the road sign, and resize the cropped images to $96\\times 96$ pixels (each pixel containing 3 values) to have all images in the same dimension.\n",
    "Note that there can be multiple road sign per image and that in the basic dataset, the speedlimit associated with each sign were not indicated, so we had to modify every .xml files by hand to be able in the end to distinguish the different speedlimits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6668e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:35:54.033568Z",
     "start_time": "2025-12-07T12:35:40.159920Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 96\n",
    "X = []\n",
    "y_all = []\n",
    "y_mask = []\n",
    "\n",
    "xml_files = sorted(glob.glob(ANN_DIR + \"/*.xml\"))\n",
    "for xml_path in xml_files:\n",
    "    filename, objects = parse_voc_xml(xml_path)\n",
    "    img_path = IMAGES_DIR + \"/\" + filename\n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    for obj in objects:\n",
    "        label = obj[\"label\"]\n",
    "        xmin, ymin, xmax, ymax = obj[\"bbox\"]\n",
    "        crop = img.crop((xmin, ymin, xmax, ymax))\n",
    "        crop = crop.resize((IMG_SIZE, IMG_SIZE))\n",
    "        X.append(np.array(crop))\n",
    "        y_all.append(label)\n",
    "        y_mask.append(\"-\" in label)\n",
    "        \n",
    "X = np.array(X)\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "print(\"Extracted images :\", X.shape)\n",
    "print(\"Labels :\", np.unique(y_all))\n",
    "print(\"Speed limits :\", np.unique(y_all[y_mask]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55b411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:35:55.149534Z",
     "start_time": "2025-12-07T12:35:54.289638Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    idx = random.randint(0, len(X)-1)\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X[idx].astype(\"uint8\"))\n",
    "    plt.title(y_all[idx])\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee31e29b53cabb5",
   "metadata": {},
   "source": [
    "### Building the Dataset\n",
    "\n",
    "All classifiers works best with values between 0 and 1.\n",
    "\n",
    "Note that we are using the label \"speedlimit\" for classification between roadsigns, meaning label 1 will not appear on the final results (it is a placeholder for first classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f10081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:35:56.194803Z",
     "start_time": "2025-12-07T12:35:55.547880Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X.astype(\"float32\") / 255.0\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_str = np.unique(y_all)\n",
    "label_str = np.append(label_str, [\"speedlimit\"])\n",
    "label_encoder.fit(label_str)\n",
    "y_encoded_all = label_encoder.transform(y_all)\n",
    "\n",
    "X_train, X_test, y_train_all, y_test_all = train_test_split(\n",
    "    X_flat, y_encoded_all, test_size=0.2, random_state=7, stratify=y_encoded_all\n",
    ")\n",
    "\n",
    "print(\"Train :\", X_train.shape, y_train_all.shape)\n",
    "print(\"Test  :\", X_test.shape, y_test_all.shape)\n",
    "print(\"Classes :\", label_encoder.classes_)\n",
    "\n",
    "y_train = np.copy(y_train_all)\n",
    "mask = np.isin(y_train, label_encoder.transform([\"speedlimit\", \"crosswalk\", \"stop\", \"trafficlight\"]))\n",
    "y_train[~mask] = label_encoder.transform([\"speedlimit\"])[0]\n",
    "\n",
    "y_test = np.copy(y_test_all)\n",
    "mask = np.isin(y_test, label_encoder.transform([\"speedlimit\", \"crosswalk\", \"stop\", \"trafficlight\"]))\n",
    "y_test[~mask] = label_encoder.transform([\"speedlimit\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545a81a6be48ee4",
   "metadata": {},
   "source": [
    "## Comparison of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16901f4c2efe359",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression\n",
    "\n",
    "Default max_iteration of LogisticRegression is 100 but it was not enough for the classifier to converge and made errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e66b68ccfe91db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:36:04.753367Z",
     "start_time": "2025-12-07T12:35:56.615903Z"
    }
   },
   "outputs": [],
   "source": [
    "cls_lr = LogisticRegression(max_iter=200)\n",
    "cls_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09712163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:36:05.511280Z",
     "start_time": "2025-12-07T12:36:05.060896Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted_lr = cls_lr.predict(X_test)\n",
    "print(classification_report(y_test, y_predicted_lr))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predicted_lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b868f9b44a44961",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052eb97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:38:06.850405Z",
     "start_time": "2025-12-07T12:36:05.613297Z"
    }
   },
   "outputs": [],
   "source": [
    "cls_svm = svm.SVC()\n",
    "cls_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ea3c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:38:38.433519Z",
     "start_time": "2025-12-07T12:38:07.150584Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted_svm = cls_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_predicted_svm))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predicted_svm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7662b467cb9c3f",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ffbfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:38:39.184039Z",
     "start_time": "2025-12-07T12:38:38.726225Z"
    }
   },
   "outputs": [],
   "source": [
    "cls_gnb = GaussianNB()\n",
    "cls_gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1691b3de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:38:40.204578Z",
     "start_time": "2025-12-07T12:38:39.291569Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted_gnb = cls_gnb.predict(X_test)\n",
    "print(classification_report(y_test, y_predicted_gnb))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predicted_gnb, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc41af3d375eba6",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors\n",
    "\n",
    "Using the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8db8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:38:40.483244Z",
     "start_time": "2025-12-07T12:38:40.427575Z"
    }
   },
   "outputs": [],
   "source": [
    "cls_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "cls_knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e852ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:38:46.796696Z",
     "start_time": "2025-12-07T12:38:40.561388Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted_knn = cls_knn.predict(X_test)\n",
    "print(classification_report(y_test, y_predicted_knn))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predicted_knn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c8fbf2fc8bb90",
   "metadata": {},
   "source": [
    "Parameters tuning to find the best accuracy (simple brutefirce over $n$ and the weight function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60078beba072c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:39:12.931282Z",
     "start_time": "2025-12-07T12:38:47.111150Z"
    }
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "for n_neighbors in range(1, 11):\n",
    "    for weights in ['uniform', 'distance']:\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_predicted_knn = knn.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_predicted_knn)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'n_neighbors': n_neighbors, 'weights': weights}\n",
    "print(f'Best accuracy: {best_accuracy}')\n",
    "print(f'Best parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ba38002ecbe41",
   "metadata": {},
   "source": [
    "## First Model Conclusion\n",
    "We find that the best classifier is the Support Vector Machine with an accuracy of 98%, even if it take a long time to run on certain machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3c1e55fb57fda",
   "metadata": {},
   "source": [
    "# Second Model\n",
    "Because the model was too inaccurate when we tried to work with all the different signs and different speedlimits, we chose to train the first model solely on the differentiation of sign types and to make a second model that would only train on the differentiation of speedlimits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4994a",
   "metadata": {},
   "source": [
    "## Building the dataset (speed limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb447395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:39:13.198442Z",
     "start_time": "2025-12-07T12:39:13.135979Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_sl = np.copy(y_train_all)\n",
    "mask = np.isin(y_train_sl, label_encoder.transform([\"speedlimit\", \"crosswalk\", \"stop\", \"trafficlight\"]))\n",
    "y_train_sl = y_train_all[~mask]\n",
    "X_train_sl = X_train[~mask]\n",
    "\n",
    "y_test_sl = np.copy(y_test_all)\n",
    "mask = np.isin(y_test_sl, label_encoder.transform([\"speedlimit\", \"crosswalk\", \"stop\", \"trafficlight\"]))\n",
    "y_test_sl = y_test_all[~mask]\n",
    "X_test_sl = X_test[~mask]\n",
    "\n",
    "print(\"Train speedlimit:\", X_train_sl.shape, y_train_sl.shape)\n",
    "print(\"Test speedlimit :\", X_test_sl.shape, y_test_sl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f976a",
   "metadata": {},
   "source": [
    "## Training the second model\n",
    "We compared each classifier and found out that the one with the best accuracy (92%) was the LogisticRegression classifier. Like in the first model we need to increase the value of maximum iterations so the model can converge, here it is 600 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4890f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:39:39.478983Z",
     "start_time": "2025-12-07T12:39:13.233596Z"
    }
   },
   "outputs": [],
   "source": [
    "cls_lr_sl = LogisticRegression(max_iter=600)\n",
    "cls_lr_sl.fit(X_train_sl, y_train_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a68b31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:39:40.570652Z",
     "start_time": "2025-12-07T12:39:39.906231Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted_lr_sl = cls_lr_sl.predict(X_test_sl)\n",
    "print(classification_report(y_test_sl, y_predicted_lr_sl))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_sl, y_predicted_lr_sl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50162cb",
   "metadata": {},
   "source": [
    "## Combining the models\n",
    "We then have to fuse both models to have a clean result at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140355e1bc22b4fa",
   "metadata": {},
   "source": [
    "### Replacing data to build the final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47ddd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:39:40.903070Z",
     "start_time": "2025-12-07T12:39:40.852697Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = np.copy(y_predicted_svm)\n",
    "mask = np.isin(y_predicted, label_encoder.transform([\"speedlimit\"]))\n",
    "y_predicted[mask] = cls_lr_sl.predict(X_test[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b679f1b",
   "metadata": {},
   "source": [
    "### Confusion matrixes (recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363035bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:39:42.329737Z",
     "start_time": "2025-12-07T12:39:40.914396Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Stage 1: Support Vector Machine, classification between road signs\")\n",
    "\n",
    "print(classification_report(y_test, y_predicted_svm))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predicted_svm)\n",
    "plt.show()\n",
    "\n",
    "print(\"Stage 2: Logistic Regression, classification between speed limits (classified by the stage 1)\")\n",
    "\n",
    "print(classification_report(y_test_sl, y_predicted_lr_sl))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_sl, y_predicted_lr_sl)\n",
    "plt.show()\n",
    "\n",
    "print(\"Total: classification between road signs and speed limits\")\n",
    "\n",
    "print(classification_report(y_test_all, y_predicted))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_all, y_predicted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c6c552a1d1f20",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "By combining both our model we find a global accuracy of 93%, which is way better than the ~80% of a single model trained on every type of signs and every speedlimits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72e1eeac869b4d",
   "metadata": {},
   "source": [
    "### After obtaining the satisfying accuracy display numbers which the model misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5189f4dd0e94865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:39:46.092587Z",
     "start_time": "2025-12-07T12:39:42.604670Z"
    }
   },
   "outputs": [],
   "source": [
    "y_missclassified_mask = y_predicted != y_test_all\n",
    "\n",
    "print(\"Total number of missclassification :\", y_missclassified_mask.sum())\n",
    "\n",
    "y_missclassified_computed = label_encoder.inverse_transform(y_predicted[y_missclassified_mask])\n",
    "y_missclassified_test = label_encoder.inverse_transform(y_test_all[y_missclassified_mask])\n",
    "X_missclassified = X_test[y_missclassified_mask]\n",
    "\n",
    "n = len(y_missclassified_computed)\n",
    "\n",
    "X_missclassified = (X_missclassified.astype(\"float32\") * 255.0).astype(\"uint8\")\n",
    "\n",
    "rows = (n + 4) // 5\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=5, figsize=(15, rows * 4))\n",
    "for i in range(n):\n",
    "    plt.subplot(rows, 5, i+1)\n",
    "    plt.imshow(X_missclassified[i].reshape(96, 96, 3))\n",
    "    plt.title(\"Predicted: \" + y_missclassified_computed[i] + \"\\nActual: \" + y_missclassified_test[i])\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(hspace=0.6)\n",
    "\n",
    "\n",
    "# Hide unused plot spots at the end\n",
    "for j in range(n, rows * 5):\n",
    "    axes.flatten()[j].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
